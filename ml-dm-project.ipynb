{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-22T11:54:07.494566Z",
     "iopub.status.busy": "2025-03-22T11:54:07.494195Z",
     "iopub.status.idle": "2025-03-22T11:54:07.910820Z",
     "shell.execute_reply": "2025-03-22T11:54:07.909682Z",
     "shell.execute_reply.started": "2025-03-22T11:54:07.494525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:11:53.843853Z",
     "iopub.status.busy": "2025-03-22T12:11:53.843471Z",
     "iopub.status.idle": "2025-03-22T12:11:54.772501Z",
     "shell.execute_reply": "2025-03-22T12:11:54.771310Z",
     "shell.execute_reply.started": "2025-03-22T12:11:53.843808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:16:30.917760Z",
     "iopub.status.busy": "2025-03-22T12:16:30.917379Z",
     "iopub.status.idle": "2025-03-22T12:16:30.922744Z",
     "shell.execute_reply": "2025-03-22T12:16:30.921210Z",
     "shell.execute_reply.started": "2025-03-22T12:16:30.917726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"agnews_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"agnews_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:05:20.048702Z",
     "iopub.status.busy": "2025-03-22T12:05:20.048336Z",
     "iopub.status.idle": "2025-03-22T12:05:21.002897Z",
     "shell.execute_reply": "2025-03-22T12:05:21.001471Z",
     "shell.execute_reply.started": "2025-03-22T12:05:20.048663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"/kaggle/input/ag-news-classification-dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:05:38.951547Z",
     "iopub.status.busy": "2025-03-22T12:05:38.951122Z",
     "iopub.status.idle": "2025-03-22T12:05:38.989595Z",
     "shell.execute_reply": "2025-03-22T12:05:38.988638Z",
     "shell.execute_reply.started": "2025-03-22T12:05:38.951514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(\"/kaggle/input/ag-news-classification-dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:16:41.406375Z",
     "iopub.status.busy": "2025-03-22T12:16:41.405970Z",
     "iopub.status.idle": "2025-03-22T12:16:41.417607Z",
     "shell.execute_reply": "2025-03-22T12:16:41.416401Z",
     "shell.execute_reply.started": "2025-03-22T12:16:41.406342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:16:57.022566Z",
     "iopub.status.busy": "2025-03-22T12:16:57.022189Z",
     "iopub.status.idle": "2025-03-22T12:16:57.033709Z",
     "shell.execute_reply": "2025-03-22T12:16:57.032649Z",
     "shell.execute_reply.started": "2025-03-22T12:16:57.022512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:07:41.146675Z",
     "iopub.status.busy": "2025-03-22T12:07:41.146270Z",
     "iopub.status.idle": "2025-03-22T12:07:41.193747Z",
     "shell.execute_reply": "2025-03-22T12:07:41.192469Z",
     "shell.execute_reply.started": "2025-03-22T12:07:41.146639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:07:50.573799Z",
     "iopub.status.busy": "2025-03-22T12:07:50.573469Z",
     "iopub.status.idle": "2025-03-22T12:07:50.585332Z",
     "shell.execute_reply": "2025-03-22T12:07:50.584295Z",
     "shell.execute_reply.started": "2025-03-22T12:07:50.573773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:08:17.785227Z",
     "iopub.status.busy": "2025-03-22T12:08:17.784840Z",
     "iopub.status.idle": "2025-03-22T12:08:17.810124Z",
     "shell.execute_reply": "2025-03-22T12:08:17.809009Z",
     "shell.execute_reply.started": "2025-03-22T12:08:17.785194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:09:16.008715Z",
     "iopub.status.busy": "2025-03-22T12:09:16.008373Z",
     "iopub.status.idle": "2025-03-22T12:09:16.017966Z",
     "shell.execute_reply": "2025-03-22T12:09:16.016665Z",
     "shell.execute_reply.started": "2025-03-22T12:09:16.008688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:10:09.367703Z",
     "iopub.status.busy": "2025-03-22T12:10:09.367381Z",
     "iopub.status.idle": "2025-03-22T12:10:09.499471Z",
     "shell.execute_reply": "2025-03-22T12:10:09.498250Z",
     "shell.execute_reply.started": "2025-03-22T12:10:09.367677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(inplace = True)\n",
    "df_test.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['Title'] + ' ' + df_train['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test['Title'] + ' ' + df_test['Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns = {'Class Index': 'label'}, inplace = True)\n",
    "df_test.rename(columns = {'Class Index': 'label'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'] - 1 \n",
    "df_test['label'] = df_test['label'] - 1\n",
    "df_train['label'].value_counts()\n",
    "df_train.drop(columns = ['Title', 'Description'], inplace = True)\n",
    "df_test.drop(columns = ['Title', 'Description'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:12:18.702531Z",
     "iopub.status.busy": "2025-03-22T12:12:18.702168Z",
     "iopub.status.idle": "2025-03-22T12:12:18.899276Z",
     "shell.execute_reply": "2025-03-22T12:12:18.897880Z",
     "shell.execute_reply.started": "2025-03-22T12:12:18.702501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df_train['label'], edgecolor='black')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:12:34.575500Z",
     "iopub.status.busy": "2025-03-22T12:12:34.574799Z",
     "iopub.status.idle": "2025-03-22T12:12:34.791749Z",
     "shell.execute_reply": "2025-03-22T12:12:34.790536Z",
     "shell.execute_reply.started": "2025-03-22T12:12:34.575453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df_test['label'], edgecolor='black')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df_train['text']))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:17:26.616752Z",
     "iopub.status.busy": "2025-03-22T12:17:26.616385Z",
     "iopub.status.idle": "2025-03-22T12:17:26.753984Z",
     "shell.execute_reply": "2025-03-22T12:17:26.752978Z",
     "shell.execute_reply.started": "2025-03-22T12:17:26.616724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contains_html(text):\n",
    "  \"\"\"Checks if a string contains HTML tags.\"\"\"\n",
    "  match = re.search('<.*?>', text)\n",
    "  return bool(match)\n",
    "\n",
    "html_rows = df_train[df_train['text'].apply(contains_html)]\n",
    "\n",
    "html_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from torch.optim import AdamW  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(df_train))\n",
    "\n",
    "df_train_copy = df_train.copy()  \n",
    "df_train = df_train_copy.iloc[:train_size]  \n",
    "df_val = df_train_copy.iloc[train_size:] \n",
    "\n",
    "print(df_train.shape)  \n",
    "print(df_val.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_label = df_train['label'].values\n",
    "train_tfidf_text = df_train['text'].values\n",
    "test_tfidf_text = df_test['text'].values\n",
    "test_tfidf_label = df_test['label'].values\n",
    "val_tfidf_text = df_val['text'].values\n",
    "val_tfidf_label = df_val['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train = vectorizer.fit_transform(train_tfidf_text)\n",
    "X_tfidf_val = vectorizer.transform(val_tfidf_text)\n",
    "X_tfidf_test = vectorizer.transform(test_tfidf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tfidf_train.shape)\n",
    "print(X_tfidf_val.shape)  \n",
    "print(X_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train = X_tfidf_train.toarray()\n",
    "X_tfidf_val = X_tfidf_val.toarray()\n",
    "X_tfidf_test = X_tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names_out()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train, X_tfidf_train[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df_train['text'].tolist() \n",
    "train_tokens = [tokenizer.tokenize(text) for text in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = df_val['text'].tolist()\n",
    "val_tokens = [tokenizer.tokenize(text) for text in val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = df_test['text'].tolist()\n",
    "test_tokens = [tokenizer.tokenize(text) for text in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode = [torch.tensor(tokenizer.encode(text, truncation=True, max_length=256)) for text in df_train['text']]\n",
    "val_encode = [torch.tensor(tokenizer.encode(text, truncation=True, max_length=256)) for text in df_val['text']]\n",
    "test_encode = [torch.tensor(tokenizer.encode(text, truncation=True, max_length=256)) for text in df_test['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequence(train_encode, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "x_val = pad_sequence(val_encode, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "x_test = pad_sequence(test_encode, batch_first=True, padding_value=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = df_train['label'].tolist()\n",
    "val_label = df_val['label'].tolist()\n",
    "test_label = df_test['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(train_label, dtype=torch.long)\n",
    "y_val = torch.tensor(val_label, dtype=torch.long)\n",
    "y_test = torch.tensor(test_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, x_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDClassifier(loss = \"log_loss\", max_iter=1, warm_start = True, learning_rate=\"constant\", eta0=0.01, random_state=42)\n",
    "\n",
    "best_accuracy = 0\n",
    "no_improvement_count = 0\n",
    "early_stopping_threshold = 5\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lr.fit(X_tfidf_train, train_tfidf_label)\n",
    "\n",
    "    train_preds = lr.predict(X_tfidf_train)\n",
    "    val_preds = lr.predict(X_tfidf_val)\n",
    "\n",
    "    train_probs = lr.predict_proba(X_tfidf_train)\n",
    "    val_probs = lr.predict_proba(X_tfidf_val)\n",
    "\n",
    "    train_loss = log_loss(train_tfidf_label, train_probs)\n",
    "    val_loss = log_loss(val_tfidf_label, val_probs)\n",
    "\n",
    "    train_accuracy = np.mean(train_preds == train_tfidf_label)\n",
    "    val_accuracy = np.mean(val_preds == val_tfidf_label)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")    \n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "    \n",
    "    if no_improvement_count >= early_stopping_threshold:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train vs Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_tfidf_train, train_tfidf_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_preds_test = rfc.predict(X_tfidf_test)\n",
    "rfc_preds_val = rfc.predict(X_tfidf_val)\n",
    "\n",
    "test_acc = np.mean(rfc_preds_test == test_tfidf_label)\n",
    "val_acc = np.mean(rfc_preds_val == val_tfidf_label)\n",
    "\n",
    "print(f\"RF - Acc: {test_acc:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimator = 1000, max_depth = 6, learning_rate = 0.1, eval_metric='mlogloss', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_tfidf_train, train_tfidf_label), (X_tfidf_val, val_tfidf_label)]\n",
    "xgb.fit(X_tfidf_train, train_tfidf_label, eval_set=eval_set, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xgb.evals_result()\n",
    "train_loss = results['validation_0']['mlogloss']\n",
    "val_loss = results['validation_1']['mlogloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"XGBoost - Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(x_train, y_train)\n",
    "val_dataset = TextDataset(x_val, y_val)\n",
    "test_dataset = TextDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_dim, hidden_dim, output_dim, num_layers = 1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embd_dim)\n",
    "        self.lstm = nn.LSTM(embd_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.dense = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        last_hidden = self.dropout(lstm_out[:, -1,  :])\n",
    "        output = self.dense(last_hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "embd_dim = 256\n",
    "hidden_dim = 512\n",
    "output_dim = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(vocab_size, embd_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = 1e-5, weight_decay=1e-4)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            texts, labels = batch  \n",
    "            texts, labels = texts.to(device), labels.to(device)  \n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions.append(outputs.argmax(dim=1))\n",
    "            targets.append(labels)\n",
    "    \n",
    "    predictions = torch.cat(predictions)\n",
    "    targets = torch.cat(targets)\n",
    "    accuracy = (predictions == targets).float().mean().item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "patience = 3\n",
    "best_val_accuracy = 0\n",
    "no_improvement_count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    lstm.train()\n",
    "    total_loss = 0\n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_accuracy = evaluate(lstm, train_loader, criterion, device)\n",
    "    val_loss, val_accuracy = evaluate(lstm, val_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy < best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        no_improvement_count = 0\n",
    "        best_model = lstm.state_dict()\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        if no_improvement_count >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "lstm.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(range(1, num_epochs+1), train_losses, 'g-', label='Training Loss')\n",
    "ax1.plot(range(1, num_epochs+1), val_losses, 'r-', label='Validation Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color='g')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "ax1.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(range(1, num_epochs+1), train_accuracies, 'b-', label='Training Accuracy')\n",
    "ax1.plot(range(1, num_epochs+1), val_accuracies, 'y-', label='Validation Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy', color='b')\n",
    "plt.title('Test Accuracy Over Epochs')\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "num_labels = 4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions.append(outputs.logits.argmax(dim=1))\n",
    "            targets.append(labels)\n",
    "\n",
    "    predictions = torch.cat(predictions)\n",
    "    targets = torch.cat(targets)\n",
    "    accuracy = (predictions == targets).float().mean().item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "patience = 3\n",
    "best_val_accuracy = 0\n",
    "no_improvement_count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_accuracy = evaluate(model, train_loader, criterion, device)\n",
    "    val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        no_improvement_count = 0\n",
    "        best_model_state = model.state_dict()  \n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        if no_improvement_count >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_model_state)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 612351,
     "sourceId": 1095715,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
